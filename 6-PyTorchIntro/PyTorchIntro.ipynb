{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorchIntro.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "xeHvTuFofyzI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PyTorch 60-Minutes Blitz Tutorial\n",
        "Adapted from https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
        "\n",
        "Contents:\n",
        "* Install dependencies \n",
        "* What is PyTorch\n",
        "* Neural Networks\n",
        "* Training a Classifier\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "50___ZiceIp7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install dependencies\n",
        "\n",
        "**Check for GPU**\n",
        "\n",
        "First make sure the nvidia-smi command returns information about the available GPU. If it does not, click Runtime > Change runtime type > Hardware accelerator > GPU. Then run the nvidia-smi command again."
      ]
    },
    {
      "metadata": {
        "id": "Ufapz-kvovJF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rAsj5LBfqE7_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Install PyTorch 0.4.1 and torchvision**"
      ]
    },
    {
      "metadata": {
        "id": "VqgKQOM_iLO6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uqy6qqMqWxs7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sg2/intro"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AVIORfPKDNiO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "80db99cf-6a48-4a24-a8c3-99c49aad17d0"
      },
      "cell_type": "code",
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)   \u001b[K\rremote: Counting objects:  28% (2/7)   \u001b[K\rremote: Counting objects:  42% (3/7)   \u001b[K\rremote: Counting objects:  57% (4/7)   \u001b[K\rremote: Counting objects:  71% (5/7)   \u001b[K\rremote: Counting objects:  85% (6/7)   \u001b[K\rremote: Counting objects: 100% (7/7)   \u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)   \u001b[K\rremote: Compressing objects: 100% (2/2)   \u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 5 (delta 2), reused 5 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  20% (1/5)   \rUnpacking objects:  40% (2/5)   \rUnpacking objects:  60% (3/5)   \rUnpacking objects:  80% (4/5)   \rUnpacking objects: 100% (5/5)   \rUnpacking objects: 100% (5/5), done.\n",
            "From https://github.com/sg2/intro\n",
            " * branch            master     -> FETCH_HEAD\n",
            "   40d11c5..5685552  master     -> origin/master\n",
            "Updating 40d11c5..5685552\n",
            "Fast-forward\n",
            " 6-PyTorchIntro/assets/mnist.png | Bin \u001b[31m0\u001b[m -> \u001b[32m16925\u001b[m bytes\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            " create mode 100644 6-PyTorchIntro/assets/mnist.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zBik5I5lYNyx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd intro/6-PyTorchIntro"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "chQ14aRqkUim",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ckt1RnjMjtCG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What is PyTorch?\n",
        "================\n",
        "\n",
        "It’s a Python-based scientific computing package targeted at two sets of\n",
        "audiences:\n",
        "\n",
        "-  A replacement for NumPy to use the power of GPUs\n",
        "-  A deep learning research platform that provides maximum flexibility\n",
        "   and speed\n",
        "\n",
        "Getting Started\n",
        "---------------\n",
        "\n",
        "Tensors are similar to NumPy’s ndarrays, with the addition being that\n",
        "Tensors can also be used on a GPU to accelerate computing.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "KFFgK2z1jwv5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yTN6qMGVkaCR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Construct a 5x3 matrix, uninitialized:"
      ]
    },
    {
      "metadata": {
        "id": "tAu96pyAkfd6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NpCFnX8Rkhkd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Construct a matrix filled zeros and of dtype long:"
      ]
    },
    {
      "metadata": {
        "id": "SGJKBDmpkj8e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = torch.zeros(5, 3, dtype=torch.long)\n",
        "print(x)\n",
        "print(x.dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kIOJMbegklk3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Construct a tensor directly from data:"
      ]
    },
    {
      "metadata": {
        "id": "jsjUXHD5koHr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "snn4V6G8kpyP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Or create a tensor based on an existing tensor. These methods will reuse properties of the input tensor, e.g. dtype, unless new values are provided by user\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "id_m5sUbldHa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
        "print(x)                                      # result has the same size\n",
        "print(x.dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i3ymMKKalgKa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Get its size:"
      ]
    },
    {
      "metadata": {
        "id": "ziWHqyt-like",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(x.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1X7_5xnslkSL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.Size`` is in fact a tuple, so it supports all tuple operations.</p></div>\n",
        "\n",
        "**Operations**\n",
        "\n",
        "There are multiple syntaxes for operations. In the following\n",
        "example, we will take a look at the addition operation.\n",
        "\n",
        "Addition: syntax 1\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "R3QE_Ja_lqRv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = torch.rand(5, 3)\n",
        "print(x + y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UIjuzeMqlwqf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Addition: syntax 2"
      ]
    },
    {
      "metadata": {
        "id": "Q31cb2V5lzHt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(torch.add(x, y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4eBNSWbQl0fW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Addition: providing an output tensor as argument"
      ]
    },
    {
      "metadata": {
        "id": "M1hNHkWml8gT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "result = torch.empty(5, 3)\n",
        "torch.add(x, y, out=result)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qiB0fvE3mkww",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Addition: in-place"
      ]
    },
    {
      "metadata": {
        "id": "qhqCN_gpmosp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# adds x to y\n",
        "y.add_(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GjQO5NdgmqP3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n",
        "    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.</p></div>\n",
        "\n",
        "You can use standard NumPy-like indexing with all bells and whistles!"
      ]
    },
    {
      "metadata": {
        "id": "P9q7HARGmy8_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(x[:, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NYbPY4TvmzVv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Resizing: If you want to resize/reshape tensor, you can use torch.view:"
      ]
    },
    {
      "metadata": {
        "id": "BxMpb8v0m1Hj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X8hxpB_Rm_hs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you have a one element tensor, use .item() to get the value as a Python number\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "e6I01gzpnBOR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P7eJGE1VnEn7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Read later:**\n",
        "\n",
        "\n",
        "  100+ Tensor operations, including transposing, indexing, slicing,\n",
        "  mathematical operations, linear algebra, random numbers, etc.,\n",
        "  are described <a href='http://pytorch.org/docs/torch'>http://pytorch.org/docs/torch</a>.\n",
        "\n",
        "NumPy Bridge\n",
        "------------\n",
        "\n",
        "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
        "\n",
        "The Torch Tensor and NumPy array will share their underlying memory\n",
        "locations, and changing one will change the other.\n",
        "\n",
        "Converting a Torch Tensor to a NumPy Array"
      ]
    },
    {
      "metadata": {
        "id": "3-NQoCzanJ6Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = torch.ones(5)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZYk3i04hng_P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "b = a.numpy()\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sEUsco9JniFY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "See how the numpy array changed in value."
      ]
    },
    {
      "metadata": {
        "id": "ei-2XQf1njwH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JPbA-Dnqnmb-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Converting NumPy Array to Torch Tensor"
      ]
    },
    {
      "metadata": {
        "id": "abO8qjCGnpOG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WCRMCITSny9u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All the Tensors on the CPU except a CharTensor support converting to\n",
        "NumPy and back.\n",
        "\n",
        "CUDA Tensors\n",
        "------------\n",
        "\n",
        "Tensors can be moved onto any device using the ``.to`` method.\n"
      ]
    },
    {
      "metadata": {
        "id": "IT8Ro1E2n7ms",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aK_VnKjY_l6r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Networks\n",
        "\n",
        "## Basic neural network with PyTorch\n",
        "\n",
        "Numpy is a great framework, but it cannot utilize GPUs to accelerate its numerical computations. For modern deep neural networks, GPUs often provide speedups of 50x or greater, so unfortunately numpy won’t be enough for modern deep learning.\n",
        "\n",
        "Here we use PyTorch Tensors to fit a two-layer network to random data. Like the numpy example above we need to manually implement the forward and backward passes through the network:"
      ]
    },
    {
      "metadata": {
        "id": "VahSeN1b_ykL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random input and output data\n",
        "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
        "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
        "\n",
        "# Randomly initialize weights\n",
        "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
        "w2 = torch.randn(H, D_out, device=device, dtype=dtype)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(500):\n",
        "    # Forward pass: compute predicted y\n",
        "    h = x.mm(w1)\n",
        "    h_relu = h.clamp(min=0)\n",
        "    y_pred = h_relu.mm(w2)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = (y_pred - y).pow(2).sum().item()\n",
        "    print(t, loss)\n",
        "\n",
        "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
        "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
        "    grad_h = grad_h_relu.clone()\n",
        "    grad_h[h < 0] = 0\n",
        "    grad_w1 = x.t().mm(grad_h)\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    w1 -= learning_rate * grad_w1\n",
        "    w2 -= learning_rate * grad_w2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PJtm4e1nA05e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## NN Module\n",
        "\n",
        "The `nn` package provides high-level abstractions over raw computational graphs that are useful for building neural networks. The `nn` package defines a set of Modules, which are roughly equivalent to neural network layers. A Module receives input Tensors and computes output Tensors, but may also hold internal state such as Tensors containing learnable parameters. The nn package also defines a set of useful loss functions that are commonly used when training neural networks.\n",
        "\n",
        "In this example we use the nn package to implement our two-layer network:"
      ]
    },
    {
      "metadata": {
        "id": "IZRpT8ToBhJZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random Tensors to hold inputs and outputs\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
        "# is a Module which contains other Modules, and applies them in sequence to\n",
        "# produce its output. Each Linear Module computes output from input using a\n",
        "# linear function, and holds internal Tensors for its weight and bias.\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "\n",
        "# The nn package also contains definitions of popular loss functions; in this\n",
        "# case we will use Mean Squared Error (MSE) as our loss function.\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "learning_rate = 1e-4\n",
        "for t in range(500):\n",
        "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
        "    # override the __call__ operator so you can call them like functions. When\n",
        "    # doing so you pass a Tensor of input data to the Module and it produces\n",
        "    # a Tensor of output data.\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
        "    # values of y, and the loss function returns a Tensor containing the\n",
        "    # loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    print(t, loss.item())\n",
        "\n",
        "    # Zero the gradients before running the backward pass.\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
        "    # parameters of the model. Internally, the parameters of each Module are stored\n",
        "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
        "    # all learnable parameters in the model.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
        "    # we can access its gradients like we did before.\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= learning_rate * param.grad"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}